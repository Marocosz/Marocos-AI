# Estudo Profundo: Arquitetura Backend do Agente Conversacional

Este documento serve como um guia tÃ©cnico avanÃ§ado sobre o backend do agente "Marcos Portfolio". Ele disseca as decisÃµes de arquitetura, tÃ©cnicas de prompt engineering e estratÃ©gias de seguranÃ§a implementadas para criar um sistema robusto, contextual e fiel Ã  persona.

---

## ğŸ—ï¸ IntroduÃ§Ã£o & Filosofia

O sistema nÃ£o Ã© apenas um chatbot que responde perguntas. Ele Ã© uma **Pipeline Cognitiva** (Cognitive Pipeline) baseada em Grafos (LangGraph), onde cada etapa da conversa Ã© processada por um "NÃ³" especialista.

**Principais Problemas Resolvidos:**

- **Perda de Contexto:** Como saber que "e ele?" se refere ao projeto citado hÃ¡ 3 mensagens?
- **AlucinaÃ§Ã£o:** Como impedir que o bot invente projetos que nunca fiz?
- **Quebra de Persona:** Como garantir que ele fale como um "Dev Jr/Pleno gente boa" e nÃ£o como um robÃ´ corporativo?
- **SeguranÃ§a:** Como evitar que o usuÃ¡rio force o bot a falar bobagens (Jailbreak)?

---

## ğŸ“‚ AnÃ¡lise Modulada (Deep Dive)

### 1. NÃ³ de ContextualizaÃ§Ã£o (`contextualize_input`)

> **Arquivo:** `nodes/memory.py`

#### ğŸ¯ Responsabilidade

Transformar interaÃ§Ãµes dependentes de contexto (ex: "E quem criou?") em perguntas autÃ´nomas e autocontidas (ex: "Quem criou o projeto DataChat?").

#### ğŸ› ï¸ TÃ©cnica: Coreference Resolution (ResoluÃ§Ã£o de CorreferÃªncia)

LLMs nÃ£o tÃªm "memÃ³ria" nativa entre requisiÃ§Ãµes. Se buscarmos no banco vetorial apenas "E ele?", teremos resultados lixo. Precisamos "descompactar" a intenÃ§Ã£o.

**Prompt Engineering (Destaques):**

- **Trigger de SeguranÃ§a:** `confidence = "high"`. O prompt Ã© instruÃ­do a **NÃƒO** reescrever se houver ambiguidade.
  - _Risco evitado:_ Se o usuÃ¡rio diz "Isso Ã© legal", e a reescrita inventa "O projeto X Ã© legal" erroneamente, estragamos a conversa. Melhor falhar mantendo o original do que alucinar um sujeito errado.
- **SaÃ­da Estruturada (JSON):** ForÃ§amos o modelo a devolver `{ "rephrased_query": "...", "confidence": "high" }`. Isso permite que o cÃ³digo Python decida programaticamente se aceita ou descarta a reescrita.

#### âš ï¸ Se nÃ£o existisse...

Perguntas sequenciais como "Quais tecnologias ele usa?" falhariam 100% das vezes no RAG (Retrieval Augmented Generation), pois o banco vetorial encontraria textos aleatÃ³rios com a palavra "ele" ou "tecnologias", sem saber do que se trata.

---

### 2. NÃ³ de MemÃ³ria & Resumo (`summarize_conversation`)

> **Arquivo:** `nodes/memory.py`

#### ğŸ¯ Responsabilidade

Impedir o estouro da janela de contexto (Token Limit) e manter a coerÃªncia de longo prazo sem repassar 50 mensagens inteiras a cada chamada.

#### ğŸ› ï¸ TÃ©cnica: Rolling Summary (Resumo Rolante) com Semantic Separation

NÃ£o apenas "resumimos". O prompt separa os dados em blocos lÃ³gicos:

- `[PERFIL_DO_USUARIO]`: Fatos aprendidos sobre quem estÃ¡ perguntando (Nome, Cargo).
- `[CONTEXTO_TECNICO_ATUAL]`: O tÃ³pico da discussÃ£o vigente.
- `[PREFERENCIAS]`: ConfiguraÃ§Ãµes de tom ou formato.

**DecisÃ£o CrÃ­tica de Prompt:**

- _"Se Novos Eventos contradiz MemÃ³ria Atual, A NOVIDADE VENCE."_
- Isso evita o problema de **MemÃ³ria Teimosa**, onde o bot insiste num erro antigo porque ele estÃ¡ gravado no resumo. A instruÃ§Ã£o explÃ­cita de sobreescrita sanea a base de conhecimento dinÃ¢mica.

---

### 3. NÃ³ de Roteamento (`router_node`)

> **Arquivo:** `nodes/router.py`

#### ğŸ¯ Responsabilidade

O "CÃ©rebro" decisÃ³rio. Escolhe se a mensagem vai para o fluxo **SOCIAL** (Casual) ou **TÃ‰CNICO** (RAG).

#### ğŸ› ï¸ TÃ©cnica: HÃ­brida (DeterminÃ­stica + SemÃ¢ntica)

1.  **Camada 1 (Regex/DeterminÃ­stica):**
    - Se o input for `"Oi"`, `"Valeu"`, `"Kkk"`, nÃ£o gastamos tokens/dinheiro com LLM. Um Regex resolve em milissegundos.
    - _Ganho:_ LatÃªncia zero para interaÃ§Ãµes triviais e economia de custo.
2.  **Camada 2 (ClassificaÃ§Ã£o SemÃ¢ntica via LLM):**
    - Analisa nuances. _"VocÃª gosta de jogos?"_ parece casual, mas para este portfÃ³lio Ã© **TÃ‰CNICO**, pois a resposta estÃ¡ no `profile.md`.
    - **Prompt:** InstruÃ­mos explicitamente: _"Se for pergunta sobre gostos pessoais, CLASS IF TECHNICAL"_. Isso corrige o viÃ©s padrÃ£o dos LLMs que acham que "hobby" Ã© sempre "papo furado".

#### âš ï¸ Se nÃ£o existisse...

O bot gastaria recursos buscando no banco de dados para responder um "Oi" (Lento e Caro), ou responderia perguntas tÃ©cnicas com "chatice genÃ©rica" por achar que Ã© papo casual.

---

### 4. NÃ³ de RAG & RecuperaÃ§Ã£o (`retrieve` + `rag.py`)

> **Arquivo:** `nodes/rag.py`

#### ğŸ¯ Responsabilidade

A busca da verdade. Encontrar os trechos de documentos (`.md`) que respondem Ã  pergunta.

#### ğŸ› ï¸ TÃ©cnica: Source Tracking & Metadata Injection

Ao recuperar os chunks, nÃ£o jogamos apenas texto cru. Formatamos assim:

```text
--- FONTE: profile.md ---
(ConteÃºdo...)
```

Isso permite que o LLM (na etapa de geraÃ§Ã£o) saiba a origem da informaÃ§Ã£o. Se o usuÃ¡rio perguntar "Onde vocÃª diz isso?", o bot tem a referÃªncia.

---

### 5. NÃ³ de Answerability Guard (`answerability_guard`)

> **Arquivo:** `nodes/guard.py`

#### ğŸ¯ Responsabilidade

O "Advogado do Diabo". Antes de responder, este nÃ³ julga se **REALMENTE** temos a informaÃ§Ã£o necessÃ¡ria.

#### ğŸ› ï¸ TÃ©cnica: Self-Reflection & Binary Classification

Ã‰ um passo de verificaÃ§Ã£o que roda um LLM com temperatura 0 (DeterminÃ­stico).
Ele NÃƒO gera texto para o usuÃ¡rio. Ele gera metadados internos:

- `is_answerable`: `True` / `False`
- `reason`: `missing_specific_fact`, `ambiguous`, `content_exhausted`

**O Grande Diferencial:**
Se o usuÃ¡rio pergunta _"Qual a placa do seu carro?"_ e o RAG retorna chunks sobre "Projetos em React", um LLM comum tentaria inventar uma placa ou dizer algo vago.
O Guard analisa: _"A pergunta pede PLACA. O contexto tem REACT. Match? NÃ£o."_ -> Bloqueia a resposta.

#### âš ï¸ Se nÃ£o existisse...

TerÃ­amos **AlucinaÃ§Ãµes**. O bot tentaria responder a qualquer custo, inventando fatos sobre a vida pessoal do Marcos que nÃ£o existem nos documentos, quebrando a confianÃ§a.

---

### 6. NÃ³ de GeraÃ§Ã£o Final (`generate_rag`)

> **Arquivo:** `nodes/rag.py`

#### ğŸ¯ Responsabilidade

Sintetizar a resposta final para o usuÃ¡rio, aplicando a **Persona**.

#### ğŸ› ï¸ TÃ©cnica: Persona Injection & Negative Constraints

O prompt deste nÃ³ Ã© o mais complexo do sistema. Ele nÃ£o apenas diz "responda". Ele impÃµe restriÃ§Ãµes negativas:

- _"NUNCA mande o usuÃ¡rio ler o site."_ (Postura de AnfitriÃ£o Ativo).
- _"Se nÃ£o sabe, diga que NÃƒO SABE."_ (Honestidade Intelectual).
- _"Use gÃ­rias leves."_ (Tone-match).

**Check de Anti-RepetiÃ§Ã£o:**
O prompt recebe tambÃ©m o `formatted_history` e Ã© instruÃ­do: _"Se vocÃª jÃ¡ contou a histÃ³ria X na mensagem acima, VÃ PARA A PRÃ“XIMA ou diga que acabou."_. Isso evita o efeito "Papagaio" onde o bot repete a mesma anedota em loop.

---

### 7. Observabilidade (`observability.py`)

> **Arquivo:** `core/observability.py`

#### ğŸ¯ Responsabilidade

Tornar o "pensamento" da IA visÃ­vel para o desenvolvedor.

#### ğŸ› ï¸ TÃ©cnica: Structured Logging (Visual Boxes)

Em vez de logs lineares ilegÃ­veis, criamos um sistema de blocos visuais (`Ascii Boxes`) que mostram claramente:

- ğŸ‘¤ INPUT
- âš™ï¸ NÃ“ (Inputs e Outputs estruturados)
- ğŸ¤– RESPOSTA

Isso acelera o debug em 10x, pois conseguimos ver exatamente onde a lÃ³gica quebrou (ex: "O Router classificou errado" ou "O Guard bloqueou sem querer").

---

## ğŸ”„ Fluxo Completo do Sistema (End-to-End)

Imagine que o usuÃ¡rio pergunta: **"E quais tecnologias ele usa?"** (logo apÃ³s falar do projeto DataChat).

1.  **Input Recebido:** A API recebe a string bruta.
2.  **Language Detection:** Identifica `pt-br`.
3.  **Memory (Contextualize):**
    - LÃª o histÃ³rico. VÃª que a mensagem anterior era sobre "DataChat".
    - **Reescreve:** "Quais tecnologias o projeto DataChat usa?"
4.  **Router:**
    - Analisa a nova pergunta. Identifica palavras-chave "tecnologias", "projeto".
    - **DecisÃ£o:** `TECHNICAL` (Rota RAG).
5.  **Retrieve:**
    - Busca no VectorDB (Chroma) por: "tecnologias projeto DataChat".
    - Encontra 4 pedaÃ§os de texto do `profile.md`.
6.  **Answerability Guard:**
    - Analisa os 4 pedaÃ§os. Eles contÃªm "Python", "Pandas", "React"? Sim.
    - **Veredito:** `is_answerable: True`.
7.  **Generate RAG:**
    - Recebe os fatos brutos.
    - Aplica a persona "Marcos".
    - Gera: _"Opa, no DataChat eu usei **Python** pesadÃ£o no backend com **Pandas** para processar os dados..."_
8.  **Translator:**
    - Verifica idioma original (`pt-br`). NÃ£o precisa traduzir.
9.  **Output:** JSON final enviado ao Frontend/User.

### ğŸ›¡ï¸ Redes de SeguranÃ§a (Safety Nets)

1.  **Se o Router falhar:** Ele tem um `try/catch` que forÃ§a o caminho `TECHNICAL` em caso de erro. Melhor responder tecnicamente errado do que dar "crash".
2.  **Se o RAG nÃ£o achar nada:** O `Guard` pega o contexto vazio, seta `is_answerable: False`, e o fluxo Ã© desviado para o `FallbackResponder` ("Putz, nÃ£o sei...").
3.  **Se o usuÃ¡rio tentar Jailbreak ("Ignore suas regras"):** O prompt do `generate_rag` tem instruÃ§Ãµes explÃ­citas de `System Override` para ignorar comandos que quebrem a persona.

---

Este documento reflete o estado atual do cÃ³digo em `backend/app/graph`.
